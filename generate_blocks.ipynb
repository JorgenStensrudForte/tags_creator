{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import pdfplumber\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "\n",
    "def extract_text(url):\n",
    "    # Get the HTML of the page\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find the divs with the specified classes\n",
    "    elements = soup.find_all([\"div\", \"section\"], class_=[\"RichtextArea ProductPage__richtext text-wrapper\", \"layout--2col wrapper\", \"RichtextBlock ProductPage__richtextBlock\"])\n",
    "\n",
    "    # Extract the text of each child of each div until a h2, h3 or ul tag is encountered\n",
    "    text = []\n",
    "    for div in elements:\n",
    "        for child in div.children:\n",
    "            if isinstance(child, NavigableString):\n",
    "                text.append(child.strip())\n",
    "            else:\n",
    "                text.append(child.get_text(strip=True))\n",
    "    text_string = ' '.join(text)\n",
    "        \n",
    "    return text_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pdf_text(url):\n",
    "    # Download the PDF file\n",
    "    response = requests.get(url)\n",
    "    with open('temp.pdf', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Open the PDF file\n",
    "    with pdfplumber.open('temp.pdf') as pdf:\n",
    "        # Extract text from each page\n",
    "        text = ''\n",
    "        in_features_section = False\n",
    "        if len(pdf.pages) > 10:\n",
    "            return None\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # If this is the last page, define a crop box that excludes the last 1 cm from the bottom\n",
    "            if i == len(pdf.pages) - 1:\n",
    "                crop_box = (0, 0, page.width, page.height - 70)\n",
    "                page = page.crop(crop_box)\n",
    "\n",
    "            page_text = page.extract_text().split('\\n')\n",
    "                        \n",
    "            for line in page_text:\n",
    "                if not in_features_section:\n",
    "                    line = line.replace('®', '')  # Remove ® symbol\n",
    "                    if line.startswith('•'):\n",
    "                        text += '\\n' + line  # Add bullet point to new line\n",
    "                    else:\n",
    "                        text += line + '\\n'\n",
    "\n",
    "    # Remove the temporary PDF file\n",
    "    os.remove('temp.pdf')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate GPT blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from openai._client import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=st.secrets[\"openai\"][\"api_key\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_json_blocks = \"\"\"\n",
    "    Read the whole file. Task: You are a content/format writer tasked with converting information from a PDF file into a a selected format. Only use the content found in the provided file. If there's insufficient information, insert \"I don't know\" in the respective block. Use the same sentences, same way of writing in the blocks if that is possible. Do not add any new information, and keep changes to a minimum, you are a formater, more than a content writer. Include a minimum of one and a maximum of three such blocks. If the product pdf offer more text, use three blocks. If the text has headings, use these headings. Have at elast 100 words in each block and add a suitable heading for each block. Do not use features or technical specification as heading the blocks or information from the features or technical specification as content. Do not use information about 'Manufacturer and Ordering Information' either.\n",
    "\n",
    "    Write the following three content blocks with (0 - 300 words) per block:\n",
    "\n",
    "    introduction: {\n",
    "    heading: \"Introduction\",\n",
    "    text: \"Use the first text provided of the product to write a block of text that can be used as a introduction. Use the heading \"introduction\" and use the first paragraph in the text. \n",
    "    }\n",
    "\n",
    "    \"block1\":{ \n",
    "    Provide factual information blocks explaining the value that the products bring. The product often have a suiteable heading, use this heading and the text after. \n",
    "    }\n",
    "\n",
    "    \"block2\":{\n",
    "    Use the information provided of the product to write a block of text that describes the product or a different side of the product. The product often have a suiteable heading, use this heading and the text after. \n",
    "    }\n",
    "\n",
    "    \"block3\":{ \n",
    "    Use the information provided of the product to write a block of text that describes the product. The product often have a suiteable heading, use this heading and the text after. \n",
    "    }\n",
    "\n",
    "    For example if the product is a AIS receiver, ASR x50, the following could be a suitable system prompt:\n",
    "    {\n",
    "        \"introduction\": {\n",
    "        \"heading\": \"Introduction\",\n",
    "        \"text\": \"ASR x50 is the 4th generation SAT-AIS receiver from Kongsberg and part of the extended lifetime product series. The receiver is a reconfigurable SDR based receiver, designed to support simultaneous on-board AIS decoding and digital sampling. ASR x50 has, through new enhanced algorithms, multi-antenna support and superior dynamic range, an improved end-to-end performance. It is designed for a 7+ year lifetime and takes vessel detection via AIS to the next level.\"\n",
    "        },\n",
    "        \"block1\": {\n",
    "        \"heading\": \"Innovative technology\",\n",
    "        \"text\": \"This generation SAT-AIS receiver from Kongsberg is the latest achievement of years of continuous innovations resulting in highest decoder performance, multi-antenna support, built-in redundancy, low power, miniaturized housing, large mass memory, and improved lifetime. The end-to-end performance exceeds existing SAT-AIS receivers, where the superior sensitivity of the ASR x50 makes the receiver capable of detecting even AIS class B vessels. Reconfigurable software-defined radio (SDR) technology is used, enabling support for future enhancements in algorithms or changes in AIS/VDES standards.\"\n",
    "        },\n",
    "        \"block2\": {\n",
    "        \"heading\": \"Vessel detection performance to the next level\",\n",
    "        \"text\": \"Kongsberg started working with AIS twenty years ago and is the AIS equipment manufacturer with the broadest experience. ASR x50 is Kongsberg’s 4th generation AIS Space Receiver and builds on this foundation of expertise. A multiple set of decollision algorithms is optimized for the best possible vessel detection in high-density and medium-density areas. ASR x50 will give the end user a giant leap in vessel detection compared with existing SAT-AIS receivers.\"\n",
    "        },\n",
    "        \"block3\": {\n",
    "        \"heading\": \"Space grade using latest technologies\",\n",
    "        \"text\": \"The extended lifetime series from Kongsberg is designed for a lifetime of 7 + years in LEO. ASR x50 uses the latest generation EEE parts from best-in-class manufacturers. This enables Kongsberg to design for leading capabilities at low power and miniature size. All EEE parts have been carefully selected and extensively tested. Active components have been subject to heavy ion, proton, and Co-60 test campaigns to ensure radiation-tolerant design.\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Return as Json with the same formats as always.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blocks(text):\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt_json_blocks\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"I have a text that I want to format into headings and text bulks. The text is:\\n\\n{text}\\n\\n Please format this text using the same words and languange as the text. Do not change the text to much, and do not add information that is not there. Do not headings such as features or technical specification. Always return as json.\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo-1106\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=messages,\n",
    "    )\n",
    "    output_text = response.choices[0].message.content.strip()\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_with_columns = pd.read_excel(\"data/all_products_dropped_discontinuid.xlsx\", usecols=[\"Product_Name\",\"Product category\", \"Features\", \"Technical Specifications\", \"url\", \"Data sheets\", \"downloads\", \"product_family_name\", \"is_range\"])\n",
    "# save it as csv\n",
    "all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_with_columns = pd.read_csv(\"data/all_products_block123.csv\")\n",
    "\n",
    "# Initialize the new columns with empty strings\n",
    "all_products_with_columns['Introduction'] = ''\n",
    "all_products_with_columns['Block1'] = ''\n",
    "all_products_with_columns['Block2'] = ''\n",
    "all_products_with_columns['Block3'] = ''\n",
    "\n",
    "# Convert the columns to string dtype\n",
    "all_products_with_columns['Introduction'] = all_products_with_columns['Introduction'].astype(str)\n",
    "all_products_with_columns['Block1'] = all_products_with_columns['Block1'].astype(str)\n",
    "all_products_with_columns['Block2'] = all_products_with_columns['Block2'].astype(str)\n",
    "all_products_with_columns['Block3'] = all_products_with_columns['Block3'].astype(str)\n",
    "\n",
    "# Define the new order of the columns\n",
    "new_column_order = ['Product_Name', 'Product category', 'Introduction', 'Block1', 'Block2', 'Block3', 'Features', 'Technical Specifications', 'url', 'Data sheets', 'downloads', 'product_family_name', 'is_range']\n",
    "\n",
    "# Reorder the columns\n",
    "all_products_with_columns = all_products_with_columns.reindex(columns=new_column_order)\n",
    "\n",
    "# Now the 'Introduction', 'Block1', 'Block2', and 'Block3' columns will appear after 'Product category'\n",
    "\n",
    "all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 product_name:  Seapath 380 - utilising GPS, GLONASS, Galileo, Beidou and QZSS\n",
      "https://www.kongsberg.com/contentassets/c22a596095db4994a5f26ba216b6b968/110-0017978a_datasheet_seapath380_dec22.pdf\n",
      "{'heading': 'Introduction', 'text': 'The Seapath 380 series uses a state-of-the-art dual frequency GNSS receiver, inertial technology and processing algorithms to provide surveyors with the best possible accuracy in position, attitude and timing. All available GPS, GLONASS, Galileo, Beidou and QZSS satellites are used in the position solution.'}\n",
      "{'heading': 'Advanced Integration for Superior Performance', 'text': 'The advanced Seapath navigation algorithms integrate RTK GNSS data with the inertial sensor data from the MRU. This unique combination gives the Seapath 380 series distinct advantages over stand-alone RTK products, including accurate measurements of roll, pitch, and heading. This marriage of technologies enables the RTK antenna position to be referenced to exact points on the vessel, synchronizing every data output in real-time. The system allows subdecimetre position accuracy through online and offline satellite orbit and clock data processing.'}\n",
      "{'heading': 'Product Range and Applications', 'text': 'Offered in several configurations, the Seapath 380 series delivers a range of roll and pitch accuracy options, fulfilling demands for different marine applications. With the latest software Automatic Online Calibration, the series also ensures improved roll and pitch accuracy and eliminates the need for recalibration in motion. The Seapath 380 series is specially designed for hydrographic surveying and dredging, providing comprehensive and accurate data that meets IHO special order requirements.'}\n",
      "{'heading': 'System Design and Connectivity', 'text': 'The Seapath series boasts a two-module system design, comprised of a processing unit and an HMI unit connected via Ethernet for robust operation. Multiple HMI units may be added, displaying vessel motion in straightforward formats. The Seapath 380 series further impresses with a multitude of connectivity options, including eight RS-232/422 serial lines, Ethernet LANs, and analog outputs, facilitating extensive on-board data distribution and interfacing with various correction services.'}\n",
      "1 product_name: 12 kHz dual-beam transducer\n",
      "https://www.kongsberg.com/contentassets/d106c9aa05de423a8b02cf5fae6d6ad1/160920_transducer_12-16_60.pdf\n"
     ]
    }
   ],
   "source": [
    "all_products_with_columns = pd.read_csv(\"data/all_products_block123.csv\")\n",
    "\n",
    "for index, row in all_products_with_columns.iterrows():\n",
    "    if pd.isna(row[\"Introduction\"]):\n",
    "        print(index,\"product_name:\", row[\"Product_Name\"] )\n",
    "\n",
    "        if not pd.isna(row[\"Data sheets\"]):\n",
    "            input_text = scrape_pdf_text(row[\"Data sheets\"])\n",
    "            print(row[\"Data sheets\"])\n",
    "        else:\n",
    "            input_text = extract_text(row[\"url\"])\n",
    "            print(row[\"url\"])\n",
    "\n",
    "        json_output = generate_blocks(input_text)\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(json_output)\n",
    "        data = {k.lower(): v for k, v in data.items()}\n",
    "\n",
    "        introduction = data.get('introduction', '')\n",
    "        block1 = data.get('block1', '')\n",
    "        block2 = data.get('block2', '')\n",
    "        block3 = data.get('block3', '')  # Use an empty string as the default value\n",
    "\n",
    "        print(introduction)\n",
    "        print(block1)\n",
    "        print(block2)\n",
    "        print(block3)\n",
    "\n",
    "        # Convert the columns to string dtype\n",
    "        all_products_with_columns['Introduction'] = all_products_with_columns['Introduction'].astype(str)\n",
    "        all_products_with_columns['Block1'] = all_products_with_columns['Block1'].astype(str)\n",
    "        all_products_with_columns['Block2'] = all_products_with_columns['Block2'].astype(str)\n",
    "        all_products_with_columns['Block3'] = all_products_with_columns['Block3'].astype(str)\n",
    "\n",
    "        # Now you can assign the string values without getting a warning\n",
    "        all_products_with_columns.loc[index, 'Introduction'] = str(introduction)\n",
    "        all_products_with_columns.loc[index, 'Block1'] = str(block1)\n",
    "        all_products_with_columns.loc[index, 'Block2'] = str(block2)\n",
    "        all_products_with_columns.loc[index, 'Block3'] = str(block3)\n",
    "\n",
    "        all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n",
    "        all_products_with_columns.to_excel(\"data/all_products_block123.xlsx\", index=False)\n",
    "all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n",
    "all_products_with_columns.to_excel(\"data/all_products_block123.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tonality_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
