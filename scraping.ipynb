{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrping av del 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " EK80 Portable EntryThe EK80 Portable Entry is all you need for ecosystem monitoring and analysis in one package â€“ at a reasonable price.  EK80 Portable Entry bundle comprises:   This is a complete rugged echo sounder with a built-in computer, GPS, and WiFi for remote operation. The core of the product is the WBT Mini, a compact EK80 wideband transceiver with four channels. The Entry bundle uses three of these channels for the 38 kHz split beam, while the last channel is used for the 200 kHz single beam.    The EK80 Portable entry is provided with the ES38-18/200-18 transducer. This is a dual-frequency transducer combining 38 and 200 kHz in one housing. The beamwidth is 18 degrees at both frequencies to secure a large sampling volume in shallow water. Combining high and low frequencies is ideal for mapping ecosystem components and separating fish from plankton.   Key features \n",
      "https://www.kongsberg.com/maritime/products/ocean-science/ocean-science/es_scientific/sci_es_transceivers/ek80-portable-entry/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "\n",
    "def extract_text(url):\n",
    "    # Get the HTML of the page\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find the divs with the specified classes\n",
    "    divs = soup.find_all(class_=[\"RichtextArea ProductPage__richtext text-wrapper\", \"layout--2col wrapper\"])\n",
    "\n",
    "    # Extract the text of each child of each div until a h2, h3 or ul tag is encountered\n",
    "    text = []\n",
    "    for div in divs:\n",
    "        for child in div.children:\n",
    "            if isinstance(child, NavigableString):\n",
    "                text.append(child.strip())\n",
    "            elif child.name in ['ul']:\n",
    "                break\n",
    "            else:\n",
    "                text.append(child.get_text(strip=True))\n",
    "    text_string = ' '.join(text)\n",
    "        \n",
    "    return text_string\n",
    "df = pd.read_csv(\"data/tags_30_11.csv\")\n",
    "number = 23\n",
    "\n",
    "print(extract_text(df[\"url\"][number]))\n",
    "\n",
    "print(df[\"url\"][number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraping av data sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.kongsberg.com/globalassets/discovery/simrad/transducers/200-and-es200/164011_200-7g.pdf']\n",
      "https://www.kongsberg.com/maritime/products/commercial-fisheries/td/200-khz/simrad-200-7g/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def find_datasheets(url):\n",
    "    # Get the HTML of the page\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find the div with the class \"Downloads\"\n",
    "    downloads_div = soup.find('div', class_=\"Downloads\")\n",
    "\n",
    "    # If the div is found, find the section with the subtitle \"Data sheet\", \"DATA SHEET\", or \"Data- and product sheets\" within this div\n",
    "    if downloads_div:\n",
    "        datasheets_subtitle = downloads_div.find('h3', class_=\"Section__subtitle\", string=re.compile(\"data sheet|data- and product sheets|Brochure\", re.I))\n",
    "\n",
    "        # If the subtitle is found, find the next sibling section\n",
    "        if datasheets_subtitle:\n",
    "            datasheets_section = datasheets_subtitle.find_next_sibling()\n",
    "\n",
    "            # If the section is found, find all links within this section\n",
    "            if datasheets_section:\n",
    "                datasheet_links = datasheets_section.find_all('a', class_=\"Downloads__itemLink\")\n",
    "\n",
    "                # If the links are found, prepend \"https://www.kongsberg.com\" to each href attribute and return the list\n",
    "                if datasheet_links:\n",
    "                    return [\"https://www.kongsberg.com\" + link.get('href') for link in datasheet_links if link.get('href').endswith('.pdf')]\n",
    "        else:\n",
    "            # If no subtitle is found, find all links where the direct child span has the text \"Datasheet\"\n",
    "            datasheet_links = downloads_div.find_all('a', class_=\"Downloads__itemLink\")\n",
    "    \n",
    "            # If the links are found, return the href attribute of the first link that ends with \".pdf\"\n",
    "            for link in datasheet_links:\n",
    "                href = link.get('href')\n",
    "                if href.endswith('.pdf'):\n",
    "                    return [\"https://www.kongsberg.com\" + href]\n",
    "\n",
    "    # If the section, the div, or the links are not found, return None\n",
    "    return None\n",
    "\n",
    "df = pd.read_csv(\"data/tags_30_11.csv\")\n",
    "number = 83\n",
    "\n",
    "print(find_datasheets(df[\"url\"][number]))\n",
    "print(df[\"url\"][number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/tags_30_11.csv\")\n",
    "\n",
    "# Add a new column \"Data sheets\" to the dataframe\n",
    "df['Data sheets'] = df['url'].apply(find_datasheets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep column url, product name and data sheets\n",
    "df = df[['url', 'Product_Name', 'Data sheets']]\n",
    "df.to_csv(\"data/data_sheets.csv\", index=False)\n",
    "df.to_excel(\"data/data_sheets.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tonality_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
