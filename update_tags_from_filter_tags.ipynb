{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup for file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import openai\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "from openai._client import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=st.secrets[\"openai\"][\"api_key\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "today = time.strftime(\"%m_%d\")\n",
    "today_hour = time.strftime(\"%m_%d_%H:%M\")\n",
    "\n",
    "# Make a folder for today's data inside the data folder\n",
    "if not os.path.exists(\"data/\" + today):\n",
    "    os.mkdir(\"data/\" + today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path_original_dataframe_csv = \"data/tags_30_11.csv\"\n",
    "file_path_original_dataframe_excel = \"data/tags_30_11.xlsx\"\n",
    "\n",
    "file_path_filter_dataframe_csv = \"filter_tags.csv\"\n",
    "file_path_filter_dataframe_excel = \"filter_tags.xlsx\"\n",
    "\n",
    "new_file_path_splitted_dataframe_excel = \"data/\"+today+\"/splitted_tags_\" + today_hour + \".xlsx\"\n",
    "new_file_path_splitted_dataframe_csv = \"data/\"+today+\"/splitted_tags_\" + today_hour + \".csv\"\n",
    "\n",
    "new_file_path_grouped_dataframe_excel = \"data/\"+today+\"/grouped_tags_\" + today_hour + \".xlsx\"\n",
    "new_file_path_grouped_dataframe_csv = \"data/\"+today+\"/grouped_tags_\" + today_hour + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dict from pickle file\n",
    "import pickle\n",
    "with open('./data/url_technical_text_dict.pkl', 'rb') as handle:\n",
    "    url_text_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explode the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_path_original_dataframe_excel, usecols=[\"Product_Name\",\"Product category\", \"url\", \"image_url\"])\n",
    "print(len(df))\n",
    "\n",
    "# Split the 'Product category' column into multiple rows\n",
    "df = df.assign(\n",
    "    **{\"Product category\": df[\"Product category\"].str.split(\",\")}\n",
    ").explode(\"Product category\")\n",
    "\n",
    "# Trim whitespace from the 'Product category' column\n",
    "df[\"Product category\"] = df[\"Product category\"].str.strip()\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make new products_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to store the tags for each product\n",
    "# df_tech_new_tags = pd.read_csv(\"./data/tags_30_11.csv\", usecols=[\"Product_Name\", \"Product category\", \"url\", \"image_url\"])\n",
    "df_tech_new_tags = df\n",
    "filter_dataframe = pd.read_csv(file_path_filter_dataframe_csv, usecols=[\"category\", \"product type\", \"technology\", \"application\"])\n",
    "\n",
    "# Set 'category' as the index of filter_dataframe for easier lookup\n",
    "filter_dataframe.set_index('category', inplace=True)\n",
    "\n",
    "# Iterate over the rows of the dataframe\n",
    "for index, row in df_tech_new_tags.iterrows():\n",
    "    print(index)\n",
    "    product_category = str(row[\"Product category\"])  # Convert to string\n",
    "    # Get the tags for the product category\n",
    "    if product_category in filter_dataframe.index:\n",
    "        category_tags = filter_dataframe.loc[product_category].to_dict()  # Use a different variable\n",
    "        print(row[\"Product_Name\"])\n",
    "        url = row[\"url\"]\n",
    "        website_text = url_text_dict.get(url, \"\")\n",
    "        print(row[\"Product category\"])\n",
    "        print(category_tags)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that generates relevant tags for products. Your responses should be a comma-separated list of tags. For example tag1, tag2, tag3, etc...\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"For the product named '{row['Product_Name']}' in the category ' {row['Product category']} ' with the following description: '{website_text}', please select up to 2 tags from each top-level category from the provided list: {category_tags}. The top-level categories include 'Product Type', 'Technology', and 'Application'. The maximum total number of tags is 6, but you are not required to use all 6. Your response should be a comma-separated list of tags. Please note: avoid using 'tag' as a tag, and do not use the top-level category names as tags.\"\n",
    "            }\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=messages\n",
    "            # response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        tags = response.choices[0].message.content.strip()\n",
    "        df_tech_new_tags.loc[index, \"product_tags\"] = tags\n",
    "        # print(row[\"Product_Name\"])\n",
    "        print(tags)\n",
    "        print(\"______________\")\n",
    "    else:\n",
    "        print(f\"Category '{product_category}' not found in filter_dataframe\")\n",
    "\n",
    "# save the dataframe as csv\n",
    "df_tech_new_tags.to_csv(new_file_path_splitted_dataframe_csv, index=False)\n",
    "df_tech_new_tags.to_excel(new_file_path_splitted_dataframe_excel, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupe the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def extract_tags(tags_str):\n",
    "    tags_obj = ast.literal_eval(tags_str)\n",
    "    if isinstance(tags_obj, dict):\n",
    "        tags_values = tags_obj.values()\n",
    "    elif isinstance(tags_obj, tuple):\n",
    "        tags_values = tags_obj\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected type {type(tags_obj)}: {tags_obj}\")\n",
    "    \n",
    "    tags_list = []\n",
    "    for value in tags_values:\n",
    "        if isinstance(value, list):\n",
    "            tags_list.append(', '.join(map(str.strip, value)))\n",
    "        elif isinstance(value, dict):\n",
    "            tags_list.append(str(value))\n",
    "        else:\n",
    "            tags_list.append(value.strip())\n",
    "    return ', '.join(tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_many_tags = pd.read_csv(new_file_path_splitted_dataframe_csv)\n",
    "print(len(df_with_many_tags))\n",
    "# df_with_many_tags['product_tags'] = df_with_many_tags['product_tags'].apply(extract_tags)\n",
    "# combine all the tags with same product_name into one row. Let the name be the same as the first row, but for tags, combine them into two lists of tags. For the category, combine them into a list of categories. For website_url, image_url, choose the first one. \n",
    "df_with_many_tags = df_with_many_tags.groupby('Product_Name').agg({\n",
    "    'product_tags': lambda x: ', '.join(set(map(lambda y: str(y).strip(), x))),\n",
    "    'Product category': lambda x: ', '.join(map(lambda y: str(y).strip(), x)),\n",
    "    'url': 'first',\n",
    "    'image_url': 'first'\n",
    "    \n",
    "}).reset_index()\n",
    "print(len(df_with_many_tags))\n",
    "\n",
    "# save to excel\n",
    "df_with_many_tags.to_excel(new_file_path_grouped_dataframe_excel, index=False)\n",
    "df_with_many_tags.to_csv(new_file_path_grouped_dataframe_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with software tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataframe do not have column \"is_software\" then merge the column from software dataframe to the dataframe on the product name column\n",
    "df_grouped_tags = pd.read_csv(new_file_path_grouped_dataframe_csv)\n",
    "#check if the column is_software exists\n",
    "if \"is_software\" not in df_grouped_tags.columns:\n",
    "    # read the software dataframe\n",
    "    df_software = pd.read_csv(\"data/tags_27_11.csv\")\n",
    "    # merge the column is_software to the dataframe on the product name column\n",
    "    df_grouped_tags = pd.merge(df_grouped_tags, df_software[[\"Product_Name\", \"is_software\"]], on=\"Product_Name\", how=\"left\")\n",
    "    # save the dataframe\n",
    "    print(df_grouped_tags.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tonality_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
