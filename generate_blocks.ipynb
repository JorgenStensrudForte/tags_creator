{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import pdfplumber\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "\n",
    "def extract_text(url):\n",
    "    # Get the HTML of the page\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "\n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Find the divs with the specified classes\n",
    "    elements = soup.find_all([\"div\", \"section\"], class_=[\"RichtextArea ProductPage__richtext text-wrapper\", \"layout--2col wrapper\", \"RichtextBlock ProductPage__richtextBlock\"])\n",
    "\n",
    "    # Extract the text of each child of each div until a h2, h3 or ul tag is encountered\n",
    "    text = []\n",
    "    for div in elements:\n",
    "        for child in div.children:\n",
    "            if isinstance(child, NavigableString):\n",
    "                text.append(child.strip())\n",
    "            else:\n",
    "                text.append(child.get_text(strip=True))\n",
    "    text_string = ' '.join(text)\n",
    "        \n",
    "    return text_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pdf_text(url):\n",
    "    # Download the PDF file\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    \n",
    "    with open('temp.pdf', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Open the PDF file\n",
    "    try:\n",
    "        with pdfplumber.open('temp.pdf') as pdf:\n",
    "            # Extract text from each page\n",
    "            text = ''\n",
    "            in_features_section = False\n",
    "            if len(pdf.pages) > 10:\n",
    "                return None\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                # If this is the last page, define a crop box that excludes the last 1 cm from the bottom\n",
    "                if i == len(pdf.pages) - 1:\n",
    "                    crop_box = (0, 0, page.width, page.height - 70)\n",
    "                    page = page.crop(crop_box)\n",
    "\n",
    "                page_text = page.extract_text().split('\\n')\n",
    "                            \n",
    "                for line in page_text:\n",
    "                    if not in_features_section:\n",
    "                        line = line.replace('®', '')  # Remove ® symbol\n",
    "                        if line.startswith('•'):\n",
    "                            text += '\\n' + line  # Add bullet point to new line\n",
    "                        else:\n",
    "                            text += line + '\\n'\n",
    "    except:\n",
    "        print(f'Error processing file from URL: {url}')\n",
    "        return None\n",
    "\n",
    "    # Remove the temporary PDF file\n",
    "    os.remove('temp.pdf')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate GPT blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_json_blocks = \"\"\"\n",
    "    Read the whole file. Task: You are a content/format writer tasked with converting information from a PDF file into a a selected format. Only use the content found in the provided file. If there's insufficient information, insert \"I don't know\" in the respective block. Use the same sentences, same way of writing in the blocks if that is possible. Do not add any new information, and keep changes to a minimum, you are a formater, more than a content writer. Include a minimum of one and a maximum of three such blocks. If the product pdf offer more text, use three blocks. If the text has headings, use these headings. Have at elast 100 words in each block and add a suitable heading for each block. Do not use features or technical specification as heading the blocks or information from the features or technical specification as content. Do not use information about 'Manufacturer and Ordering Information' either.You do not need to use all the text to write the blocks, use the text that is most suitable.\n",
    "\n",
    "    Write the following four content blocks with (0 - 300 words) per block:\n",
    "\n",
    "    introduction: {\n",
    "    heading: \"Introduction\",\n",
    "    text: \"Use the first text provided of the product to write a block of text that can be used as a introduction. Use the heading \"introduction\" and use the first paragraph in the text. \n",
    "    }\n",
    "\n",
    "    \"block1\":{ \n",
    "    Provide factual information blocks explaining the value that the products bring. The product often have a suiteable heading, use this heading and the text after. \n",
    "    }\n",
    "\n",
    "    \"block2\":{\n",
    "    Use the information provided of the product to write a block of text that describes the product or a different side of the product. The product often have a suiteable heading, use this heading and the text after. \n",
    "    }\n",
    "\n",
    "    \"block3\":{ \n",
    "    Use the information provided of the product to write a block of text that describes the product. The product often have a suiteable heading, use this heading and the text after. \n",
    "    }\n",
    "\n",
    "    For example if the product is a AIS receiver, ASR x50, the following could be a suitable system prompt:\n",
    "    {\n",
    "        \"introduction\": {\n",
    "        \"heading\": \"Introduction\",\n",
    "        \"text\": \"ASR x50 is the 4th generation SAT-AIS receiver from Kongsberg and part of the extended lifetime product series. The receiver is a reconfigurable SDR based receiver, designed to support simultaneous on-board AIS decoding and digital sampling. ASR x50 has, through new enhanced algorithms, multi-antenna support and superior dynamic range, an improved end-to-end performance. It is designed for a 7+ year lifetime and takes vessel detection via AIS to the next level.\"\n",
    "        },\n",
    "        \"block1\": {\n",
    "        \"heading\": \"Innovative technology\",\n",
    "        \"text\": \"This generation SAT-AIS receiver from Kongsberg is the latest achievement of years of continuous innovations resulting in highest decoder performance, multi-antenna support, built-in redundancy, low power, miniaturized housing, large mass memory, and improved lifetime. The end-to-end performance exceeds existing SAT-AIS receivers, where the superior sensitivity of the ASR x50 makes the receiver capable of detecting even AIS class B vessels. Reconfigurable software-defined radio (SDR) technology is used, enabling support for future enhancements in algorithms or changes in AIS/VDES standards.\"\n",
    "        },\n",
    "        \"block2\": {\n",
    "        \"heading\": \"Vessel detection performance to the next level\",\n",
    "        \"text\": \"Kongsberg started working with AIS twenty years ago and is the AIS equipment manufacturer with the broadest experience. ASR x50 is Kongsberg’s 4th generation AIS Space Receiver and builds on this foundation of expertise. A multiple set of decollision algorithms is optimized for the best possible vessel detection in high-density and medium-density areas. ASR x50 will give the end user a giant leap in vessel detection compared with existing SAT-AIS receivers.\"\n",
    "        },\n",
    "        \"block3\": {\n",
    "        \"heading\": \"Space grade using latest technologies\",\n",
    "        \"text\": \"The extended lifetime series from Kongsberg is designed for a lifetime of 7 + years in LEO. ASR x50 uses the latest generation EEE parts from best-in-class manufacturers. This enables Kongsberg to design for leading capabilities at low power and miniature size. All EEE parts have been carefully selected and extensively tested. Active components have been subject to heavy ion, proton, and Co-60 test campaigns to ensure radiation-tolerant design.\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Return as Json with the same formats as always.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blocks_azure(text):\n",
    "    import os\n",
    "    from openai import OpenAI\n",
    "    from openai import AzureOpenAI\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    deployment_name = \"gpt-4-turbo-1106-preview\"  # This will correspond to the custom name you chose for your deployment when you deployed a model.\n",
    "\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=\"https://da-openai-test.openai.azure.com/\",\n",
    "        api_key=\"5a90b85ba420469c9b36438e238d70fe\",\n",
    "        api_version=\"2023-05-15\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt_json_blocks\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"I have a text that I want to format into headings and text bulks. The text is:\\n\\n{text}\\n\\n Please format this text using the same words and languange as the text. Do not change the text to much, and do not add information that is not there. Do not headings such as features or technical specification. Always return as json.\"\n",
    "                }\n",
    "            ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.1,\n",
    "        top_p=0.1,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blocks_openai(text):\n",
    "    import streamlit as st\n",
    "    import pandas as pd\n",
    "    from openai._client import OpenAI\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=st.secrets[\"openai\"][\"api_key\"],\n",
    "    )\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt_json_blocks\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"I have a text that I want to format into headings and text bulks. The text is:\\n\\n{text}\\n\\n Please format this text using the same words and languange as the text. Do not change the text to much, and do not add information that is not there. Do not headings such as features or technical specification. Always return as json.\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-3.5-turbo-1106\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=messages,\n",
    "    )\n",
    "    output_text = response.choices[0].message.content.strip()\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_products_with_columns = pd.read_excel(\"data/all_products_dropped_discontinuid.xlsx\", usecols=[\"Product_Name\",\"Product category\", \"Features\", \"Technical Specifications\", \"url\", \"Data sheets\", \"downloads\", \"product_family_name\", \"is_range\"])\n",
    "# # save it as csv\n",
    "# all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_products_with_columns = pd.read_csv(\"data/all_products_block123.csv\")\n",
    "\n",
    "# # Initialize the new columns with empty strings\n",
    "# all_products_with_columns['Introduction'] = ''\n",
    "# all_products_with_columns['Block1'] = ''\n",
    "# all_products_with_columns['Block2'] = ''\n",
    "# all_products_with_columns['Block3'] = ''\n",
    "\n",
    "# # Convert the columns to string dtype\n",
    "# all_products_with_columns['Introduction'] = all_products_with_columns['Introduction'].astype(str)\n",
    "# all_products_with_columns['Block1'] = all_products_with_columns['Block1'].astype(str)\n",
    "# all_products_with_columns['Block2'] = all_products_with_columns['Block2'].astype(str)\n",
    "# all_products_with_columns['Block3'] = all_products_with_columns['Block3'].astype(str)\n",
    "\n",
    "# # Define the new order of the columns\n",
    "# new_column_order = ['Product_Name', 'Product category', 'Introduction', 'Block1', 'Block2', 'Block3', 'Features', 'Technical Specifications', 'url', 'Data sheets', 'downloads', 'product_family_name', 'is_range']\n",
    "\n",
    "# # Reorder the columns\n",
    "# all_products_with_columns = all_products_with_columns.reindex(columns=new_column_order)\n",
    "\n",
    "# # Now the 'Introduction', 'Block1', 'Block2', and 'Block3' columns will appear after 'Product category'\n",
    "\n",
    "# all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_with_columns = pd.read_csv(\"data/all_products_block123.csv\")\n",
    "\n",
    "for index, row in all_products_with_columns.iterrows():\n",
    "    if pd.isna(row[\"Introduction\"]):\n",
    "        print(index,\"product_name:\", row[\"Product_Name\"] )\n",
    "\n",
    "        if not pd.isna(row[\"Data sheets\"]):\n",
    "            input_text = scrape_pdf_text(row[\"Data sheets\"])\n",
    "            if input_text is None:\n",
    "                input_text = extract_text(row[\"url\"])\n",
    "                print(row[\"url\"])\n",
    "            else:\n",
    "                print(row[\"Data sheets\"])\n",
    "        else:\n",
    "            input_text = extract_text(row[\"url\"])\n",
    "            print(row[\"url\"])\n",
    "\n",
    "        json_output = generate_blocks_openai(input_text)\n",
    "        # Parse the JSON data\n",
    "        data = json.loads(json_output)\n",
    "        data = {k.lower(): v for k, v in data.items()}\n",
    "\n",
    "        introduction = data.get('introduction', '')\n",
    "        block1 = data.get('block1', '')\n",
    "        block2 = data.get('block2', '')\n",
    "        block3 = data.get('block3', '')  # Use an empty string as the default value\n",
    "\n",
    "        print(introduction)\n",
    "        print(block1)\n",
    "        print(block2)\n",
    "        print(block3)\n",
    "\n",
    "        # Convert the columns to string dtype\n",
    "        all_products_with_columns['Introduction'] = all_products_with_columns['Introduction'].astype(str)\n",
    "        all_products_with_columns['Block1'] = all_products_with_columns['Block1'].astype(str)\n",
    "        all_products_with_columns['Block2'] = all_products_with_columns['Block2'].astype(str)\n",
    "        all_products_with_columns['Block3'] = all_products_with_columns['Block3'].astype(str)\n",
    "\n",
    "        # Now you can assign the string values without getting a warning\n",
    "        all_products_with_columns.loc[index, 'Introduction'] = str(introduction)\n",
    "        all_products_with_columns.loc[index, 'Block1'] = str(block1)\n",
    "        all_products_with_columns.loc[index, 'Block2'] = str(block2)\n",
    "        all_products_with_columns.loc[index, 'Block3'] = str(block3)\n",
    "\n",
    "        all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n",
    "        all_products_with_columns.to_excel(\"data/all_products_block123.xlsx\", index=False)\n",
    "all_products_with_columns.to_csv(\"data/all_products_block123.csv\", index=False)\n",
    "all_products_with_columns.to_excel(\"data/all_products_block123.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tonality_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
